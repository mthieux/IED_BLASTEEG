---
title: "IED-ERP-GAMM"
author: "Marine Thieux"
date: "2025-03-28"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(patchwork)
library(ggeffects)
library(emmeans)
library(mgcv)
library(itsadug)
```

# Datas

# Importation

```{r}
# Define the main directory path
path_dir <- "/Volumes/crnldata/eduwell/Epilepto/Stabilo_EEG/data_processed/EEG_CLEAN"

# Initialize a list to hold data from all files
data_list <- list()

# Get the list of subdirectories
subdirs <- list.dirs(path_dir, full.names = TRUE, recursive = FALSE)

# Initialize file counter
file_counter <- 1

# Loop through each subdirectory
for (dir in subdirs) {
  # Define file paths for "without IED" and "with IED" conditions
  file_paths_without_ied <- file.path(dir, paste0(1:3, "_epochs_without_IED.csv"))
  file_paths_with_ied <- file.path(dir, paste0(1:3, "_epochs_with_IED.csv"))

  # Process "with IED" files
  for (file_with in file_paths_with_ied) {
    if (file.exists(file_with)) {
      message("Processing: ", file_with, " as 'with' IED")
      
      # Read and process the file
      data <- read.csv2(file_with, sep = ",") %>%
        dplyr::select(-X, -condition) %>%
        gather(key = "channel", value = "ampl", -time, -epoch) %>%
        mutate(
          session = substr(basename(file_with), 1, 1),
          IED = "with",
          time = as.numeric(time),
          session = as.factor(session),
          IED = as.factor(IED),
          epoch = as.factor(epoch),
          channel = as.factor(channel),
          ampl = as.numeric(ampl),
          patname = as.factor(basename(dir))
        )
      
      # Store the processed data
      data_list[[file_counter]] <- data
      file_counter <- file_counter + 1
      rm(data)
    } else {
      message("File not found: ", file_with)
    }
  }

  # Process "without IED" files
  for (file_without in file_paths_without_ied) {
    if (file.exists(file_without)) {
      message("Processing: ", file_without, " as 'without' IED")
      
      # Read and process the file
      data <- read.csv2(file_without, sep = ",") %>%
        dplyr::select(-X, -condition) %>%
        gather(key = "channel", value = "ampl", -time, -epoch) %>%
        mutate(
          session = substr(basename(file_without), 1, 1),
          IED = "without",
          time = as.numeric(time),
          session = as.factor(session),
          IED = as.factor(IED),
          epoch = as.factor(epoch),
          channel = as.factor(channel),
          ampl = as.numeric(ampl),
          patname = as.factor(basename(dir))
        )
      
      # Store the processed data
      data_list[[file_counter]] <- data
      file_counter <- file_counter + 1
      rm(data)
    } else {
      message("File not found: ", file_without)
    }
  }
}

# Combine all processed data into a single data frame
datas <- do.call(rbind, data_list)

# Filter out unwanted channels
datas <- datas %>%
  filter(!channel %in% c("EMG1.", "EMG2.", "ECG1."))

# Check
print(length(data_list))
print(sapply(data_list, nrow))

# Clean up unused variables
rm(data_list, file_counter, path_dir, subdirs, dir, file_paths_with_ied, file_paths_without_ied, file_with, file_without)

# Output the final dataset
message("Processing complete. Final dataset ready.")

```

```{r}
datas %>%
  filter(patname %in% c("EPI_007", ## Subjects with bad Pz quality
                        "EPI_020",
                       "EPI_024",
                       "EPI_033",
                       "EPI_053",
                       "EPI_071",
                       "EPI_072",
                       "EPI_106",
                       "EPI_136",
                       "EPI_050", # Subjects excluded from behavioral analysis
                      "EPI_090",
                      "EPI_091",
                      "EPI_092",
                      "EPI_097",
                      "EPI_098",
                      "EPI_107",
                      "EPI_108",
                      "EPI_111",
                      "EPI_122",
                      "EPI_124",
                      "EPI_128",
                      "EPI_130",
                      "EPI_138",
                      "EPI_140",
                      "EPI_141")) %>%
  summarise(patname = unique(as.factor(patname))) -> badpzqual

datas %>%
  filter(!patname %in% badpzqual$patname) %>%
  droplevels() -> datas
```

# Display
```{r}
# Grand average / channels
datas %>%
  group_by(IED, channel, time) %>%
  summarise(ampl_avg = mean(ampl)) %>%
  ggplot(aes(x = time, y = ampl_avg, color = channel)) +
  geom_hline(yintercept = 0) +
  geom_line(size = 0.3) +
  geom_vline(xintercept = 0) +
  geom_vline(xintercept = -0.7, linetype = "dotdash") +
  theme(legend.position = "none") +
  facet_grid(row = vars(IED))
```

```{r}
# Grand average - Pz.    
datas %>%
  filter(channel == c("Pz")) %>%
  group_by(IED, time) %>%
  summarise(ampl_avg = mean(ampl),
            ampl_sd  = sd(ampl) ) %>%
  ggplot(aes(x = time, y = ampl_avg, fill = IED)) +
  geom_ribbon(aes(x = time, ymin = ampl_avg-ampl_sd, ymax = ampl_avg+ampl_sd, color = IED), alpha = 0.2, size = 0.1) +
  geom_line(aes(color = IED), size = 0.5) +
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = 0) +
  ggtitle("Grand average - Pz -")
```


```{r}
theme_eeg <- function(){
  list(
    see::theme_modern() +
    theme(axis.line.y = element_blank()),
    geom_vline(xintercept = 0, linetype="dashed")
  )
}

plot_model <- function(model, data){

  raw_data <- data %>%
    group_by(time, IED) %>%
    mutate(Average = mean(ampl)) %>%
    ungroup()

  p1 <- model %>%
    modelbased::estimate_link(target = c("IED", "time"), 
                              length = 200) %>%
    ggplot(aes(x = time, y = Predicted)) +
    geom_ribbon(aes(ymin = CI_low, ymax = CI_high, fill = IED), 
               alpha = 0) +
    geom_line(aes(color = IED)) +
    scale_color_manual(values = c("with" = "#993356", "without" = "#8da0cb")) +
    scale_fill_manual(values = c("with" = "#993356", "without" = "#8da0cb")) +
    theme_eeg()

  data_diff <- model %>%
    modelbased::estimate_contrasts(contrast = "IED", at = "time", 
                                   p_adjust = "FDR", length = 300) %>%
    mutate(
      Limit = pmin(abs(CI_low), abs(CI_high)),
      Positive = as.numeric(ifelse(CI_low  > 0,  Limit, NA)),
      Negative = as.numeric(ifelse(CI_high < 0, -Limit, NA)))

  p2 <- data_diff %>%
    ggplot(aes(x = time, y = Difference)) +
    geom_ribbon(aes(ymin = 0, ymax = Positive, fill = "without < with"), alpha = 0.4) +
    geom_ribbon(aes(ymin = Negative, ymax = 0, fill = "without > with"), alpha = 0.4) +
    geom_ribbon(aes(ymin = CI_low, ymax = CI_high), alpha = 0.2) +
    geom_line() +
    geom_hline(yintercept = 0) +
    theme_eeg() +
    theme(axis.line.x = element_blank()) +
    scale_fill_manual("Significant difference (p < .05)",
                      values=c("without < with" = "#00C853",
                               "without > with" = "#f44336"))
  
  p1 / p2
}
```

# LM
```{r}
# LM with time modelized using splines
datas.light <- datas %>%
  filter(time > -0.2 & time < 0.8) %>%
  droplevels()

model <- lm(ampl ~ IED * splines::bs(time, df = 0.05 * 600), 
            data = filter(datas.light, channel == "Pz"))

plot_model(model, datas.light)
```

# GAM - Scale T distribution

```{r}
datas.light %>%
  subset(channel == c("Pz", "P3", "P4")) %>%
  droplevels() -> datas_pz

model.gamm.randpat.autocorr.scalet <- mgcv::bam(
  ampl ~ s(time, by = IED, k = 20, bs = "cr", m = 1) +
         IED +
         s(time, patname, k = 20, bs = "fs", m = 1),
  data = datas_pz,
  rho = 0.98,  
  AR.start = datas_pz$start.event,
  family = "scat",
  nthreads =  parallel::detectCores(),
  discrete = TRUE,  # Makes it much faster
  method = "fREML", # Faster than default REML
  select = TRUE     # Automatic smoothing selection
)
```


```{r}
summary(model.gamm.randpat.autocorr.scalet)
```


```{r}
appraise(model.gamm.randpat.autocorr.scalet)
```

```{r}
draw(model.gamm.randpat.autocorr.scalet, residuals = F) & 
  theme_bw() + 
  theme(legend.position = "none")
```

```{r}
# ## to check : 
# plot(model.gamm.randpat.autocorr.scalet, select = 3, main = "IED : without     by subject")
# abline(h = 0)
# abline(v = 0)
# plot(model.gamm.randpat.autocorr.scalet, select = 4, main = "IED : with     by subject")
# abline(h = 0)
# abline(v = 0)

plot.gam(model.gamm.randpat.autocorr.scalet, 
         select=3, all.terms=TRUE, rug=FALSE)

plot_parametric(model.gamm.randpat.autocorr.scalet, pred = list(IED = c("with", "without")))

plot(ggemmeans(model.gamm.randpat.autocorr.scalet,
               terms = c("time","IED")))
```
```{r}
model.gamm.randpat.autocorr.scalet.01 <- mgcv::bam(
  ampl ~ s(time, k = 20, bs = "cr", m = 1) +
         IED +
         s(time, patname, k = 20, bs = "fs", m = 1),
  data = datas_pz,
  rho = 0.98,  
  AR.start = datas_pz$start.event,
  family = "scat",
  nthreads =  parallel::detectCores(),
  discrete = TRUE,  # Makes it much faster
  method = "fREML", # Faster than default REML
  select = TRUE     # Automatic smoothing selection
)


model.gamm.randpat.autocorr.scalet.02 <- mgcv::bam(
  ampl ~ s(time,  k = 20, bs = "cr", m = 1) +
         s(time, patname, k = 20, bs = "fs", m = 1),
  data = datas_pz,
  rho = 0.98,  
  AR.start = datas_pz$start.event,
  family = "scat",
  nthreads =  parallel::detectCores(),
  discrete = TRUE,  # Makes it much faster
  method = "fREML", # Faster than default REML
  select = TRUE     # Automatic smoothing selection
)


model.gamm.randpat.autocorr.scalet.03 <- mgcv::bam(
  ampl ~ s(time, by = IED, k = 20, bs = "cr", m = 1) +
         s(time, patname, k = 20, bs = "fs", m = 1),
  data = datas_pz,
  rho = 0.98,  
  AR.start = datas_pz$start.event,
  family = "scat",
  nthreads =  parallel::detectCores(),
  discrete = TRUE,  # Makes it much faster
  method = "fREML", # Faster than default REML
  select = TRUE     # Automatic smoothing selection
)
```

# Comparisons 
```{r}
# Dans ce cas, il n'y a pas de statistique car quand le SCORE et le DF d'un modèle sont plus petit que l'autre modèle, alors le premier est statistiquement meilleur. Si il y a divergeance alors on calcule un chisquare test: pchisq(2 * (score1 - score2), abs(df1 - df2), lower.tail = F)
# Donc ici, l'ajout du facteur **IED** améliore le modèle, par conséquentt il y a un effet **IED**.   #pchisq(2 * (1962073 - 1962053), abs(2), lower.tail = F)

compareML(model.gamm.randpat.autocorr.scalet.01,
          model.gamm.randpat.autocorr.scalet.02,
          suggest.report = T,
          print.output = T,
          signif.stars = T)$table

compareML(model.gamm.randpat.autocorr.scalet.02,
          model.gamm.randpat.autocorr.scalet.03,
          suggest.report = T,
          print.output = T,
          signif.stars = T)$table

compareML(model.gamm.randpat.autocorr.scalet.01,
          model.gamm.randpat.autocorr.scalet.03,
          suggest.report = T,
          print.output = T,
          signif.stars = T)$table

compareML(model.gamm.randpat.autocorr.scalet.01,
          model.gamm.randpat.autocorr.scalet,
          suggest.report = T,
          print.output = T,
          signif.stars = T)$table


compareML(model.gamm.randpat.autocorr.scalet.02,
          model.gamm.randpat.autocorr.scalet,
          suggest.report = T,
          print.output = T,
          signif.stars = T)$table

compareML(model.gamm.randpat.autocorr.scalet.03,
          model.gamm.randpat.autocorr.scalet,
          suggest.report = T,
          print.output = T,
          signif.stars = T)$table
```


```{r}
par(mfrow=c(1,2), cex=1.1)

plot_smooth(model.gamm.randpat.autocorr.scalet, 
            view = "time", rug = F, plot_all = "IED",
            rm.ranef = F,
            n.grid = 600,
            main = "with random")

plot_diff(model.gamm.randpat.autocorr.scalet, 
          view = "time", 
          comp = list(IED = c("with", "without")),
          rm.ranef = F,
          n.grid = 600,
          sim.ci = F)
```


# Values Post-hoc

```{r}
emm.02 <- emmeans(model.gamm.randpat.autocorr.scalet,
                  ~ IED | time, 
                  at = list(time = seq(from = 0.2, to = 0.8, by = 0.05)))

pairs(emm.02) %>%
  as.data.frame() %>%
  knitr::kable()

des_cont <- c(list("without-with" = c(-1, 1)))
test(contrast(regrid(emm.02), des_cont, adjust = "FDR"))
```


```{r}

# find max latency
find.time.max <- function(ggemmeans.out, groupe) {
  
  pred.val  <- ggemmeans.out$predicted[ggemmeans.out$group == groupe]
  pred.time <- ggemmeans.out$x[ggemmeans.out$group == groupe]
  
  out <- pred.time[pred.val == max(pred.val)]
  
}

plotme<- ggemmeans(model.gamm.randpat.autocorr.scalet,
                      terms = c("time","IED"))
plot(plotme) +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  scale_color_manual(values = c("with" = "#993356", "without" = "#8da0cb")) +
  scale_fill_manual(values = c("with" = "#993356", "without" = "#8da0cb")) +
  labs(
    title = "",
    x = "Time (s)",       
    y = "Predicted amplitude (uV)" 
  ) +
  theme_minimal()+
  theme(legend.position = c(0.9, 0.95),
    plot.title = element_text(size = 16, face = "bold"),       # Title size
    axis.title = element_text(size = 14),                      # Axis label size
    axis.text = element_text(size = 12),                       # Axis tick text size
    legend.title = element_text(size = 13),                    # Legend title size
    legend.text = element_text(size = 12)) -> FigA

  #geom_vline(xintercept = find.time.max(plotme, "with"),
  #           color = "red",
  #            linetype = "dotdash") +
  # geom_vline(xintercept = find.time.max(plotme, "without"),
  #            color = "blue",
  #            linetype = "dotdash")
```

# Post-Hoc (CGPT)
## Difference smooths == differences in predicted values between IED levels across time.
```{r}
### Ampl is generally lower in trial with (vs without) IED. 
### But here, we see an interaction between time and IED : specific time points exhibit stronger differences (significant = if the 95%  confidence interval for the difference excludes zero, it indicates a significant difference at those time points.)


par(mfrow = c(1,1), cex = 1)

plot_smooth(model.gamm.randpat.autocorr.scalet, 
            view = "time", rug = FALSE, plot_all = "IED",
            rm.ranef = FALSE,
            n.grid = 600,
            col = c("steelblue", "tomato"),   # Set custom colors for "with" and "without"
            main = "With Random Effects",
            legend_plot_all = TRUE)     

plot_diff(model.gamm.randpat.autocorr.scalet, 
          view = "time",
          comp = list(IED = c("with", "without")),
          main = "",
          ylab = "Amplitude difference",
          xlab = "Time (s)",
          col = "black",           # Customize line color
          lwd = 2,                 # Line width for difference curve
          rm.ranef = F,
          n.grid = 600,
         # sim.ci = F, 
          cex.axis = 1.2,
          cex.lab = 1.2) 
```


```{r}
library(ggplotify)
library(patchwork)


as.ggplot(function() {
  plot_diff(model.gamm.randpat.autocorr.scalet, 
            view = "time",
            comp = list(IED = c("with", "without")),
            main = "",
            ylab = "Amplitude difference",
            xlab = "Time (s)",
            col = "black",
            lwd = 2,
            rm.ranef = FALSE,
            n.grid = 600,
            cex.axis = 1.2,
            cex.lab = 1.2)
}) -> FigB

```


# Bootstrap (from CGPT)
```{r}
# Define the original model fitting function
fit_gam <- function(data) {
  mgcv::bam(
          ampl ~ s(time, by = IED, k = 20, bs = "cr", m = 1) +
                 IED +
                 s(time, patname, k = 20, bs = "fs", m = 1),
          data = datas_pz,
          rho = 0.98,  
          AR.start = datas_pz$start.event,
          family = "scat",
          nthreads =  parallel::detectCores(),
          discrete = TRUE,  # Makes it much faster
          method = "fREML", # Faster than default REML
          select = TRUE     # Automatic smoothing selection
        )
}

# Define a function to extract the desired output from the fitted model
# This example extracts the model's estimated coefficients
get_coefficients <- function(model) {
  coef(model)
}

# Define the bootstrapping function
bootstrap_gam <- function(data, n_bootstrap = 100) {
  boot_coefs <- replicate(n_bootstrap, {
    # Resample the data with replacement
    boot_data <- data[sample(nrow(data), replace = TRUE), ]
    # Fit the model to the bootstrapped data
    model <- fit_gam(boot_data)
    # Extract the coefficients (or other parameters as desired)
    get_coefficients(model)
  }, simplify = "matrix")
  
  # Return the matrix of bootstrapped coefficients
  return(boot_coefs)
}

# Run bootstrapping
set.seed(42)  # For reproducibility
boot_results <- bootstrap_gam(datas_pz, n_bootstrap = 100)

# Calculate summary statistics
boot_means <- rowMeans(boot_results)
boot_ci <- apply(boot_results, 1, quantile, probs = c(0.025, 0.975))

# Print the bootstrapped confidence intervals
boot_ci
```

```{r}
bootstrap_smooths <- function(data, n_bootstrap = 100, time_grid = seq(min(data$time), max(data$time), length.out = 600)) {
  boot_smooths <- replicate(n_bootstrap, {
    boot_data <- data[sample(nrow(data), replace = TRUE), ]
    model <- fit_gam(boot_data)
    
    pred_data <- expand.grid(
      time = time_grid,
      IED = unique(data$IED),  
      patname = unique(data$patname)[1]  
    )
  
    preds <- predict(model, newdata = pred_data, se.fit = TRUE)
    data.frame(time = pred_data$time, IED = pred_data$IED, fit = preds$fit)
  }, simplify = FALSE)
  
  boot_smooths_df <- do.call(rbind, boot_smooths)
  return(boot_smooths_df)
}

set.seed(42)
boot_smooth_results <- bootstrap_smooths(datas_pz, n_bootstrap = 100)
```

```{r}
# Compute mean and confidence intervals
smooth_summary <- boot_smooth_results %>%
  group_by(time, IED) %>%
  summarise(
    Mean = mean(fit),
    Lower = quantile(fit, 0.025),
    Upper = quantile(fit, 0.975),
    .groups = "drop"
  )

# Plot smooths for each IED condition
ggplot(smooth_summary, aes(x = time, y = Mean, color = IED, fill = IED)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = Lower, ymax = Upper), alpha = 2) +
  labs(title = "Bootstrapped Smooths by IED Condition",
       x = "Time (ms)",
       y = "Estimated Amplitude") +
  theme_minimal()


```

```{r}
# # Assuming 'boot_results' contains the bootstrapped coefficients
# boot_coefs_df <- as.data.frame(t(boot_results))
# colnames(boot_coefs_df) <- names(boot_means)
# 
# # Compute summary stats (mean and 95% CI)
# coef_summary <- data.frame(
#   Coefficient = names(boot_means),
#   Mean = rowMeans(boot_coefs_df),
#   Lower = apply(boot_coefs_df, 1, quantile, probs = 0.025),
#   Upper = apply(boot_coefs_df, 1, quantile, probs = 0.975)
# )
# 
# # Plot bootstrapped coefficients with CIs
# ggplot(coef_summary, aes(x = Coefficient, y = Mean)) +
#   geom_point(color = "blue", size = 3) +
#   geom_errorbar(aes(ymin = Lower, ymax = Upper), width = 0.2, color = "red") +
#   labs(title = "Bootstrapped Coefficients with 95% CI",
#        x = "Model Coefficients",
#        y = "Coefficient Value") +
#   theme_minimal() +
#   coord_flip()  # Flip for better readability

```

```{r}
# Define a new function to get predicted values instead of coefficients
get_predictions <- function(model, new_data) {
  predict(model, newdata = new_data, type = "response")
}

# Update bootstrap_gam to use get_predictions instead
bootstrap_predictions <- function(data, new_data, n_bootstrap = 100) {
  boot_preds <- replicate(n_bootstrap, {
    boot_data <- data[sample(nrow(data), replace = TRUE), ]
    model <- fit_gam(boot_data)
    get_predictions(model, new_data)
  }, simplify = "matrix")

  return(boot_preds)
}

# Define new_data with desired values for prediction
new_data <- expand.grid(time = seq(min(datas_pz$time), max(datas_pz$time), length.out = 100),
                        IED = unique(datas_pz$IED),
                        patname = unique(datas_pz$patname))

# Run bootstrapping for predictions
boot_pred_results <- bootstrap_predictions(datas_pz, new_data, n_bootstrap = 100)

# Calculate summary statistics for predictions
boot_pred_means <- rowMeans(boot_pred_results)
boot_pred_ci <- apply(boot_pred_results, 1, quantile, probs = c(0.025, 0.975))

```

#######
```{r}
# Define the original model fitting function
fit_gam <- function(data) {
  mgcv::bam(
          ampl ~ s(time, by = IED, k = 20, bs = "cr", m = 1) +
                 IED +
                 s(time, patname, k = 20, bs = "fs", m = 1),
          data = data,  # Use bootstrapped data
          rho = 0.98,  
          AR.start = data$start.event,
          family = "scat",
          nthreads = parallel::detectCores(),
          discrete = TRUE,  
          method = "fREML", 
          select = TRUE     
        )
}

# Define the function to extract coefficients
get_coefficients <- function(model) {
  coef(model)
}

# Define bootstrapping function to resample and fit the model
bootstrap_gam <- function(data, n_bootstrap = 100) {
  boot_coefs <- replicate(n_bootstrap, {
    # Resample the data with replacement
    boot_data <- data[sample(nrow(data), replace = TRUE), ]
    # Fit the model to the bootstrapped data
    model <- fit_gam(boot_data)
    # Extract the coefficients
    get_coefficients(model)
  }, simplify = "matrix")
  
  return(boot_coefs)
}

# Run bootstrapping with 100 iterations
set.seed(42)  # For reproducibility
boot_results <- bootstrap_gam(datas_pz, n_bootstrap = 100)

# Calculate summary statistics: Mean & 95% CI for coefficients
boot_means <- rowMeans(boot_results)
boot_ci <- apply(boot_results, 1, quantile, probs = c(0.025, 0.975))

# Print the bootstrapped coefficients' CI
boot_ci

```

```{r}
# Assuming boot_smooth_results is the output from your bootstrap_smooths function
smooth_summary <- boot_smooth_results %>%
  group_by(time, IED) %>%
  summarise(
    Mean = mean(fit),
    Lower = quantile(fit, 0.025),
    Upper = quantile(fit, 0.975),
    .groups = "drop"
  )

# Plot smooths for each IED condition
ggplot(smooth_summary, aes(x = time, y = Mean, color = IED, fill = IED)) +
  geom_line(size = 1) +
  geom_ribbon(aes(ymin = Lower, ymax = Upper), alpha = 0.2) +
  labs(title = "Bootstrapped Smooths by IED Condition",
       x = "Time (ms)",
       y = "Estimated Amplitude") +
  theme_minimal()

# Compute the difference between IED conditions (with vs without)
diff_summary <- smooth_summary %>%
  pivot_wider(names_from = "IED", values_from = c("Mean", "Lower", "Upper")) %>%
  mutate(
    Diff = Mean_with - Mean_without,
    Lower = Lower_with - Upper_without,
    Upper = Upper_with - Lower_without
  )

# Plot the difference (with vs without IED)
ggplot(diff_summary, aes(x = time, y = Diff)) +
  geom_line(color = "blue", size = 1) +
  geom_ribbon(aes(ymin = Lower, ymax = Upper), alpha = 0.8, fill = "red") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(title = "Bootstrapped Difference Between IED Conditions",
       x = "Time (ms)",
       y = "Estimated Difference") +
  theme_minimal()

ggplot(diff_summary, aes(x = time, y = Diff)) +
  geom_line(color = "blue", size = 1) +
  # Confidence intervals as dashed lines (not ribbon)
  geom_line(aes(y = Lower), linetype = "dashed", color = "red", size = 0.8) +  # Lower CI line
  geom_line(aes(y = Upper), linetype = "dashed", color = "red", size = 0.8) +  # Upper CI line
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = "Bootstrapped Difference Between IED Conditions",
    x = "Time (ms)",
    y = "Estimated Difference"
  ) +
  theme_minimal()


```

```{r}
# Convert boot_ci to dataframe
time_points <- seq(min(datas_pz$time), max(datas_pz$time), length.out = 680)

smooth_summary <- data.frame(
  time = time_points,
  Lower = boot_ci[1, ],  # Lower bound (2.5% percentile)
  Upper = boot_ci[2, ],  # Upper bound (97.5% percentile)
  Mean = rowMeans(boot_results)  # Mean across bootstrap samples
)

# Plot with ggplot2
library(ggplot2)
ggplot(smooth_summary, aes(x = time, y = Mean)) +
  geom_line(color = "blue", size = 1) +
  geom_ribbon(aes(ymin = Lower, ymax = Upper), alpha = 0.2, fill = "red") +
  labs(title = "Bootstrapped ERP Smooth",
       x = "Time (ms)",
       y = "Estimated Amplitude") +
  theme_minimal()

```
```{r}
# Find peak amplitude and corresponding time
peak_index <- which.max(boot_means)  # Index of max amplitude
peak_amplitude <- boot_means[peak_index]  # Peak amplitude value
peak_time <- time_points[peak_index]  # Time at which peak occurs

cat("Peak amplitude:", peak_amplitude, "at", peak_time, "ms")

# Find time points where the 95% CI does not include zero
sig_time_indices <- which(boot_ci[1, ] > 0 | boot_ci[2, ] < 0)
sig_time_range <- range(time_points[sig_time_indices])

cat("Significant time range:", sig_time_range[1], "-", sig_time_range[2], "ms")

mean_amplitude <- mean(boot_means)
sd_amplitude <- sd(boot_means)

cat("Mean ERP amplitude:", mean_amplitude, "±", sd_amplitude)

"The final Generalized Additive Model (GAM) was bootstrapped 100 times to estimate variability in the ERP response. The model-estimated ERP waveform revealed a peak amplitude of 2.749 µV at Y ms (Figure X). The mean ERP amplitude across all time points was Z µV ± W µV (SD). A significant effect was observed between A–B ms, where the 95% confidence interval (CI) did not include zero, indicating a robust IED-related modulation of the P3 component."

```


## Bootstrap with permutation method 
```{r}
library(mgcv)
library(itsadug)
library(dplyr)

# Function to fit your original model
fit_gam <- function(data) {
  bam(
    ampl ~ s(time, by = IED, k = 20, bs = "cr", m = 1) +
          IED +
          s(time, patname, k = 20, bs = "fs", m = 1),
    data = data,
    rho = 0.98,
    AR.start = data$start.event,
    family = "scat",
    nthreads = parallel::detectCores(),
    discrete = TRUE,
    method = "fREML",
    select = TRUE
  )
}

# Function to extract number of significant clusters using plot_diff()
get_n_significant_clusters <- function(model) {
  suppressMessages({
    diff_plot <- plot_diff(
      model,
      view = "time",
      comp = list(IED = c("with", "without")),
      n.grid = 600,
      sim.ci = TRUE,
      print.summary = FALSE
    )
  })

  # `plot_diff()` returns an object with $sig set to TRUE where difference is significant
  sig_vector <- diff_plot$sig
  time_vector <- diff_plot$time

  # Find continuous stretches of TRUE values (clusters)
  sig_rle <- rle(sig_vector)
  n_clusters <- sum(sig_rle$values)

  return(n_clusters)
}

# Main permutation test function
permute_labels_plotdiff <- function(data, n_iter = 100) {
  message("Fitting model with true labels...")
  model_obs <- fit_gam(data)
  observed_clusters <- get_n_significant_clusters(model_obs)

  message("Running permutations...")
  permuted_cluster_counts <- numeric(n_iter)

  for (i in 1:n_iter) {
    message("Permutation ", i)
    perm_data <- data
    perm_data$IED <- sample(perm_data$IED)  # Randomly shuffle labels

    model_perm <- tryCatch(fit_gam(perm_data), error = function(e) NULL)

    if (!is.null(model_perm)) {
      n_clusters <- get_n_significant_clusters(model_perm)
      permuted_cluster_counts[i] <- n_clusters
    } else {
      permuted_cluster_counts[i] <- NA
    }
  }

  # Compute how many permuted models had the same or more significant clusters
  n_matching_or_more <- sum(permuted_cluster_counts >= observed_clusters, na.rm = TRUE)
  p_value <- n_matching_or_more / n_iter

  list(
    observed_n_clusters = observed_clusters,
    permuted_cluster_counts = permuted_cluster_counts,
    p_value = p_value
  )
}

# Run the analysis
set.seed(123)
perm_results <- permute_labels_plotdiff(datas_pz, n_iter = 100)

# Print result
cat("Observed number of significant time clusters:", perm_results$observed_n_clusters, "\n")
cat("Proportion of permutations with as many or more clusters:", perm_results$p_value, "\n")

```

```{r}
hist(perm_results$permuted_cluster_counts, breaks = 20,
     main = "Permutation Distribution: Number of Significant Clusters",
     xlab = "Number of Significant Clusters",
     col = "lightblue")
abline(v = perm_results$observed_n_clusters, col = "red", lwd = 2)

```

```{r}
# Load required libraries
library(mgcv)
library(dplyr)
library(tidyr)
library(purrr)

# Define the original model-fitting function
fit_gam <- function(data) {
  mgcv::bam(
    ampl ~ s(time, by = IED, k = 20, bs = "cr", m = 1) +
           IED +
           s(time, patname, k = 20, bs = "fs", m = 1),
    data = data,
    rho = 0.98,  
    AR.start = data$start.event,
    family = "scat",
    nthreads = parallel::detectCores(),
    discrete = TRUE,
    method = "fREML",
    select = TRUE
  )
}

# Statistic to extract from model: for example, max difference at any timepoint
extract_statistic <- function(model, data) {
  # Create prediction grid
  time_grid <- seq(min(data$time), max(data$time), length.out = 600)
  pred_data <- expand.grid(
    time = time_grid,
    IED = c("with", "without"),
    patname = unique(data$patname)[1]
  )
  preds <- predict(model, newdata = pred_data)
  
  pred_df <- cbind(pred_data, fit = preds)
  
  # Pivot to get difference between IED conditions
  diff_df <- pred_df %>%
    pivot_wider(names_from = IED, values_from = fit) %>%
    mutate(diff = with - without)
  
  # Return max absolute difference as test statistic
  max(abs(diff_df$diff))
}

# Main permutation bootstrapping function
permute_labels_bootstrap <- function(data, n_iter = 100) {
  observed_model <- fit_gam(data)
  observed_stat <- extract_statistic(observed_model, data)

  permuted_stats <- replicate(n_iter, {
    # Shuffle IED labels while keeping the same proportion
    perm_data <- data
    perm_data$IED <- sample(data$IED)  # simple shuffle, preserves counts
    perm_model <- fit_gam(perm_data)
    extract_statistic(perm_model, perm_data)
  })

  # Compare observed stat to permutation null distribution
  p_value <- mean(permuted_stats >= observed_stat)

  list(
    observed = observed_stat,
    permuted = permuted_stats,
    p_value = p_value
  )
}

# Run the permutation bootstrapping
set.seed(42)
perm_results <- permute_labels_bootstrap(datas_pz, n_iter = 100)

# Show results
cat("Observed max difference:", perm_results$observed, "\n")
cat("P-value (proportion of permuted stats >= observed):", perm_results$p_value, "\n")

# Optional: visualize
hist(perm_results$permuted, breaks = 20,
     main = "Permutation Null Distribution of Max Difference",
     xlab = "Max Absolute Difference", col = "skyblue")
abline(v = perm_results$observed, col = "red", lwd = 2)

```

```{r}
library(mgcv)
library(dplyr)
library(tidyr)
library(ggplot2)
library(purrr)

# 1. Define model fitting function
fit_gam <- function(data) {
  mgcv::bam(
    ampl ~ s(time, by = IED, k = 20, bs = "cr", m = 1) +
      IED +
      s(time, patname, k = 20, bs = "fs", m = 1),
    data = data,
    rho = 0.98,
    AR.start = data$start.event,
    family = "scat",
    nthreads = parallel::detectCores(),
    discrete = TRUE,
    method = "fREML",
    select = TRUE
  )
}

# 2. Define prediction grid
time_grid <- seq(min(datas_pz$time), max(datas_pz$time), length.out = 600)
pred_data <- expand.grid(
  time = time_grid,
  IED = c("with", "without"),
  patname = unique(datas_pz$patname)[1]  # arbitrary subject
)

# 3. Get observed model and difference
observed_model <- fit_gam(datas_pz)
observed_preds <- predict(observed_model, newdata = pred_data)
observed_df <- cbind(pred_data, fit = observed_preds) %>%
  pivot_wider(names_from = IED, values_from = fit) %>%
  mutate(diff = with - without)

# 4. Run permutations
n_iter <- 100
perm_diffs <- replicate(n_iter, {
  perm_data <- datas_pz
  perm_data$IED <- sample(datas_pz$IED)  # shuffle labels
  perm_model <- fit_gam(perm_data)
  perm_preds <- predict(perm_model, newdata = pred_data)
  perm_df <- cbind(pred_data, fit = perm_preds) %>%
    pivot_wider(names_from = IED, values_from = fit) %>%
    mutate(diff = with - without)
  perm_df$diff
}, simplify = "matrix")

# 5. Get null distribution percentiles (per timepoint)
perm_CI <- apply(perm_diffs, 1, quantile, probs = c(0.025, 0.975))  # rows: timepoints

# 6. Add significance column to observed_df
observed_df <- observed_df %>%
  mutate(
    lower_CI = perm_CI[1, ],
    upper_CI = perm_CI[2, ],
    sig = ifelse(diff < lower_CI | diff > upper_CI, TRUE, FALSE)
  )

# 7. Plot!
ggplot(observed_df, aes(x = time, y = diff)) +
  geom_line(color = "darkblue", size = 1) +
  geom_ribbon(aes(ymin = lower_CI, ymax = upper_CI), fill = "skyblue", alpha = 0.3) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point(data = subset(observed_df, sig), aes(x = time, y = diff),
             color = "red", size = 1.2, shape = 16, alpha = 0.8) +
  labs(title = "Difference Curve (With vs Without IED) with Time-Resolved Significance",
       x = "Time (s)",
       y = "Amplitude Difference (µV)") +
  theme_minimal()

```

# Figure 4
```{r}

# Get model-based difference with CI from plot_diff()
model_ci_df <- plot_diff(
  model.gamm.randpat.autocorr.scalet,
  view = "time",
  comp = list(IED = c("with", "without")),
  rm.ranef = FALSE,
  n.grid = 600,
  return.data = TRUE  
)

model_ci_df <- model_ci_df %>%
  mutate(
    model_fit = est,
    model_CI_low = est - CI,
    model_CI_up  = est + CI, 
    model_sig = model_CI_low > 0 | model_CI_up < 0 
  )

#Join model-based CI with your permutation-based plot data
combined_df <- observed_df %>%
  left_join(model_ci_df, by = "time")


ggplot(combined_df, aes(x = time)) +
  geom_ribbon(aes(ymin = lower_CI, ymax = upper_CI), fill = "#8da0cb", alpha = 0.3) + 
  geom_ribbon(aes(ymin = model_CI_low, ymax = model_CI_up), fill = "grey", alpha = 0.4) +  
  geom_line(aes(y = diff), color = "grey30", size = 3) +  
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +  
  geom_vline(xintercept = 0, color = "black") + 
  geom_point(data = subset(combined_df, sig),
             aes(x = time, y = diff),
             color = "tomato3", size = 1, shape = 16, alpha = 0.8) +  
  geom_tile(data = filter(model_ci_df, model_sig),
            aes(y = -2.5), height = 0.02, width = 0.01,
            fill = "tomato2", alpha = 0.8) + 
  labs(x = "Time (s)", y = "Amplitude Difference (µV)") +
  theme_minimal(base_size = 16) + 
  scale_x_continuous(breaks = seq(-0.2, 0.8, by = 0.2)) +  
  scale_y_continuous(breaks = seq(0, -2.5, by = -0.5)) + 
  theme(axis.text = element_text(size = 14),  
        axis.title = element_text(size = 16),  
        plot.title = element_text(size = 18))  -> FigB


plot(plotme) +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  scale_color_manual(values = c("with" = "#993356", "without" = "#8da0cb")) +
  scale_fill_manual(values = c("with" = "#993356", "without" = "#8da0cb")) +
  labs(
    title = "",
    x = "Time (s)",       
    y = "Predicted amplitude (uV)" 
  ) +
  theme_minimal(base_size = 16) + 
  scale_x_continuous(breaks = seq(-0.2, 0.8, by = 0.2)) +  
  scale_y_continuous(breaks = seq(-5, 5, by = 1.5)) + 
  theme(legend.position = c(0.9, 0.85),
        axis.text = element_text(size = 14),  
        axis.title = element_text(size = 16),  
        plot.title = element_text(size = 18)) -> FigA


library(patchwork)
(FigA / FigB) + 
  plot_annotation(
    tag_levels = 'A',              # Tags A and B
    tag_suffix = ')',
    theme = theme(plot.tag = element_text(size = 16, face = "bold", hjust = -0.1))  # Adjust tag appearance
  ) -> Fig4

```


```{r}
library(mgcv)
library(dplyr)
library(tidyr)
library(ggplot2)
library(parallel)

# 1. Fit the observed model
fit_gam <- function(data) {
  bam(
    ampl ~ s(time, by = IED, k = 20, bs = "cr", m = 1) +
      IED +
      s(time, patname, k = 20, bs = "fs", m = 1),
    data = data,
    rho = 0.98,
    AR.start = data$start.event,
    family = "scat",
    nthreads = detectCores(),
    discrete = TRUE,
    method = "fREML",
    select = TRUE
  )
}

# 2. Prediction grid
time_grid <- seq(min(datas_pz$time), max(datas_pz$time), length.out = 600)
pred_data <- expand.grid(
  time = time_grid,
  IED = c("with", "without"),
  patname = unique(datas_pz$patname)[1]  # dummy subject
)

# 3. Fit observed model and compute predictions
observed_model <- fit_gam(datas_pz)
observed_preds <- predict(observed_model, newdata = pred_data)
pred_df <- cbind(pred_data, fit = observed_preds)

# 4. Spread wide and compute difference
diff_df <- pred_df %>%
  pivot_wider(names_from = IED, values_from = fit) %>%
  mutate(diff = with - without)

# 5. Run permutations to compute null distribution
n_iter <- 10
perm_diffs <- replicate(n_iter, {
  perm_data <- datas_pz
  perm_data$IED <- sample(datas_pz$IED)
  perm_model <- fit_gam(perm_data)
  perm_preds <- predict(perm_model, newdata = pred_data)
  perm_df <- cbind(pred_data, fit = perm_preds) %>%
    pivot_wider(names_from = IED, values_from = fit) %>%
    mutate(diff = with - without)
  perm_df$diff
}, simplify = "matrix")

# 6. Compute 95% CI from permutations
perm_CI <- apply(perm_diffs, 1, quantile, probs = c(0.025, 0.975))
diff_df$lower_CI <- perm_CI[1, ]
diff_df$upper_CI <- perm_CI[2, ]
diff_df$sig <- diff_df$diff < diff_df$lower_CI | diff_df$diff > diff_df$upper_CI

# 7. Add ERP curve info to diff_df for plotting
erp_plot_df <- pred_df

# 8. Plot ERP curves and difference with sig overlay (faceted)
ggplot() +
  # --- Panel 1: ERP curves ---
  geom_line(data = erp_plot_df, aes(x = time, y = fit, color = IED), size = 1) +
  facet_wrap(~"ERP Curves") +
  labs(y = "Estimated Amplitude (µV)", x = NULL) +
  theme_minimal() +
  theme(strip.text = element_text(face = "bold")) +

  # --- Panel 2: Difference curve ---
  geom_line(data = diff_df, aes(x = time, y = diff), color = "darkblue", size = 1, inherit.aes = FALSE) +
  geom_ribbon(data = diff_df, aes(x = time, ymin = lower_CI, ymax = upper_CI), fill = "lightblue", alpha = 0.3, inherit.aes = FALSE) +
  geom_point(data = subset(diff_df, sig), aes(x = time, y = diff), color = "red", size = 1.2, shape = 16, inherit.aes = FALSE) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  facet_wrap(~"Difference (With - Without IED)") +
  labs(y = "Amplitude Difference (µV)", x = "Time (s)")

```

