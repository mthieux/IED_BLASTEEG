{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------\n",
    "# BLAST-EEG\n",
    "## Prepocessing and epoching\n",
    "\n",
    "Author: Marine Thieux\n",
    "\n",
    "Reviewer/Assistant engineer: Lucie Martinet\n",
    "\n",
    "# -----------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13.1\n",
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "from datetime import  timezone, timedelta\n",
    "import neo\n",
    "import logging\n",
    "import pandas as pd\n",
    "from tkinter import filedialog # to select the files and directory paths\n",
    "\n",
    "# to generate windows and explore the results easily\n",
    "import matplotlib\n",
    "matplotlib.use(\"Qt5Agg\")\n",
    "from PyQt5.QtWidgets  import QMessageBox  # in the pyqt4 tutorials\n",
    "\n",
    "print(neo.__version__) # run with 0.13.1 \n",
    "print(mne.__version__) # run with 1.7.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters to personalise to read and write data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected file path: \n",
      "Selected base directory path: \n"
     ]
    }
   ],
   "source": [
    "# -----------------\n",
    "# Parameters\n",
    "# -----------------\n",
    "# Entry file\n",
    "# Where to read data\n",
    "file_path = filedialog.askopenfilename(title = \"Select the file to process.\")\n",
    "\n",
    "# Results directory, including the preproc data\n",
    "# Where to save the preproc results data\n",
    "\n",
    "base_directory_path = filedialog.askdirectory(title = \"Select the directory to store the results.\")\n",
    "\n",
    "# Print results for confirmation\n",
    "print(f\"Selected file path: {file_path}\")\n",
    "print(f\"Selected base directory path: {base_directory_path}\")\n",
    "\n",
    "Chans    = ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'T3', 'C3', 'Cz', 'C4', 'T4', 'T5', 'P3', \n",
    "            'Pz', 'P4', 'T6', 'O1', 'O2', 'EMG1+', 'ECG1+']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import datas from .TRC (with neo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annotations(eeg_micromed) :\n",
    "    # Triggers collect\n",
    "    events_time_l = []\n",
    "    description_l = []\n",
    "    duration_l = []\n",
    "\n",
    "    for e in eeg_micromed._events :\n",
    "        ev_time = np.asarray(e.times.magnitude)\n",
    "        events_time_l.append(ev_time- float(eeg_micromed._analogsignals[0].t_start)) #* sFreq) # To get sample number from time\n",
    "        description_l.append( np.asarray(e.labels))\n",
    "        duration_l.append(np.asarray(np.full(shape = len(ev_time), fill_value = 0.0)))\n",
    "\n",
    "    events_time = np.concatenate(events_time_l)\n",
    "    description = np.concatenate(description_l)\n",
    "    duration = np.concatenate(duration_l)\n",
    "    onset = events_time\n",
    "    annotations = mne.Annotations(onset = onset,\n",
    "                                  duration = duration, \n",
    "                                  description = description,\n",
    "                                  orig_time = eeg_micromed.rec_datetime.replace(tzinfo = timezone.utc) + timedelta(seconds = float(eeg_micromed.analogsignals[0]._t_start)))\n",
    "    return annotations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_micromed_mneObject(filename): \n",
    "\n",
    "    # NEO import of raw data\n",
    "    eeg_micromed = neo.MicromedIO(filename = filename).read_segment()\n",
    "    eeg_micromed.annotate(material = \"micromed\")  \n",
    "    # Get informations and data to convert it to MNE needs\n",
    "    # Channels names and types\n",
    "    chan = list()\n",
    "    for cc in range(np.size(eeg_micromed.analogsignals[0].array_annotations[\"channel_names\"])):\n",
    "        chan.append(eeg_micromed.analogsignals[0].array_annotations[\"channel_names\"][cc])\n",
    "\n",
    "    # Sample frequency\n",
    "    sFreq = eeg_micromed.analogsignals[0].sampling_rate \n",
    "\n",
    "    # Data\n",
    "    convert_fac = 1. * eeg_micromed.analogsignals[0].units\n",
    "    convert_fac.units = 'V' # to volts\n",
    "    data = np.asarray(eeg_micromed.analogsignals[0].segment._analogsignals[0]).transpose()\n",
    " \n",
    "    data = data * convert_fac.magnitude  \n",
    "\n",
    "    raw_info = mne.create_info(chan, sFreq, ch_types=\"eeg\")   \n",
    "    raw_info.set_meas_date(eeg_micromed.rec_datetime.replace(tzinfo = timezone.utc) + timedelta(seconds = float(eeg_micromed.analogsignals[0]._t_start)) )\n",
    " \n",
    "    raw = mne.io.RawArray(data, raw_info, verbose = 1)\n",
    "\n",
    "    annotations = create_annotations(eeg_micromed)\n",
    "    \n",
    "    raw.set_annotations(annotations)\n",
    "\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = convert_micromed_mneObject(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channels / montage selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of channels that actually exist in the raw data\n",
    "existing_channels = [chan for chan in Chans if chan in raw.ch_names]\n",
    "\n",
    "# If there are any matching channels, pick them\n",
    "if existing_channels:\n",
    "    raw.pick(existing_channels)\n",
    "else:\n",
    "    print(\"None of the channels in the 'Chans' list are present in the raw data.\")\n",
    "chtype = {'EMG1+': 'emg', 'ECG1+': 'ecg'}\n",
    "raw.set_channel_types(chtype)\n",
    "\n",
    "raw.set_montage(\"standard_1020\") # Apply a template montage \n",
    "raw.set_eeg_reference('average') # Set the reference\n",
    "\n",
    "# delete bad channels manually \n",
    "scalings = dict(eeg = 50e-6)\n",
    "raw.plot(duration = 30, scalings = scalings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High pass and low pass filtering\n",
    "raw.filter(l_freq = 1., h_freq = 70, h_trans_bandwidth = 'auto', l_trans_bandwidth = 'auto', filter_length = 'auto', phase = 'zero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask if we apply the notch filter depending on the existance of 50Hz pic in the psd\n",
    "raw.compute_psd().plot()\n",
    "qm = QMessageBox()\n",
    "\n",
    "qm.setText(\"Do you want to apply a notch filter based on 50Hz?\")\n",
    "qm.setStandardButtons(QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No)\n",
    "ret = 0\n",
    "ret = qm.exec()\n",
    "\n",
    "print(\"Type ret : \", type(ret), ret)\n",
    "if ret == QMessageBox.StandardButton.Yes: \n",
    "    raw.notch_filter(np.arange(50, int(raw.info['sfreq']/2)-1, 50), filter_length = 'auto', phase = 'zero') # notch\n",
    "    print(\"Notch filter applied\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling at 256Hz\n",
    "orig_raw = raw.copy()\n",
    "raw = raw.resample(sfreq = 256)\n",
    "raw.plot(duration = 30, scalings = scalings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export preprocessed raw to .fif (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionnal step\n",
    "qm = QMessageBox()\n",
    "\n",
    "qm.setText(\"Do you want to save your work in a .fif file ?\")\n",
    "qm.setStandardButtons(QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No)\n",
    "save_bool = 0\n",
    "save_bool = qm.exec()\n",
    "if save_bool == \"y\" :\n",
    "    # Extract the EPI number and file name from the input file path\n",
    "    parts = file_path.split('/')\n",
    "    epi_number = parts[-2]  \n",
    "    filename = parts[-1] \n",
    "\n",
    "    # Construct the new file path\n",
    "    new_filename = filename.replace('.TRC', '.fif')\n",
    "    new_file_path = os.path.join(base_directory_path, epi_number, new_filename).replace(\"\\\\\", \"/\") # replace for those who work on windows\n",
    "\n",
    "    # Ensure the target directory exists\n",
    "    os.makedirs(os.path.dirname(new_file_path), exist_ok=True)\n",
    "\n",
    "    # Save the preprocessed raw data\n",
    "    raw.save(new_file_path, overwrite=True)\n",
    "\n",
    "    print(f\"Preprocessed data saved to: {new_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to assign event IDs based on the first letter of the description\n",
    "def assign_event_id(description):\n",
    "    first_letter = description[0]\n",
    "    if first_letter == \"b\":\n",
    "        return 77\n",
    "    elif first_letter == \"a\" or first_letter == \"c\" or first_letter == \"e\" :\n",
    "        return 66\n",
    "    elif first_letter == \"d\" or first_letter == \"f\" :\n",
    "        return 77\n",
    "    elif description in [\"101\", \"102\", \"103\", \"104\", \"105\"]:\n",
    "        return 100\n",
    "    else:\n",
    "        return None  # Ignore other annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure correct pairing of start and end events\n",
    "def make_paired_events (all_ied_events) :\n",
    "    paired_events = []\n",
    "    current_start = None\n",
    "\n",
    "    for event_time, event_type in all_ied_events:\n",
    "        if event_type == 'start':\n",
    "            # Set current start when a \"start\" event is encountered\n",
    "            if current_start is None:\n",
    "                current_start = event_time\n",
    "            else:\n",
    "                # If we encounter another \"start\" without an \"end\", we ignore the previous one\n",
    "                print(f\"Warning: Unmatched start event at {current_start} ignored.\")\n",
    "                current_start = event_time  # Reset with the new start event\n",
    "        elif event_type == 'end':\n",
    "            if current_start is not None:\n",
    "                # Pair this \"end\" with the current \"start\"\n",
    "                if event_time > current_start:\n",
    "                    paired_events.append((current_start, event_time))\n",
    "                    current_start = None  # Reset the current start after a successful pair\n",
    "                else:\n",
    "                    # If the \"end\" comes before the \"start\", ignore it (shouldn't happen with sorted events)\n",
    "                    print(f\"Warning: End event at {event_time} comes before the start event.\")\n",
    "            else:\n",
    "                # Ignore \"end\" events that have no matching \"start\"\n",
    "                print(f\"Warning: Unmatched end event at {event_time} ignored.\")\n",
    "    return paired_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paired_events (paired_events, raw):\n",
    "    if paired_events:\n",
    "        start_ied_events, end_ied_events = zip(*paired_events)\n",
    "        start_ied_events = list(start_ied_events)\n",
    "        end_ied_events = list(end_ied_events)\n",
    "\n",
    "        # Calculate durations\n",
    "        ied_durations = [end - start for start, end in zip(start_ied_events, end_ied_events)]\n",
    "\n",
    "        # Create new annotations that span from IED_start to IED_end\n",
    "        ied_annotation = mne.Annotations(\n",
    "            onset = start_ied_events,  # Start times\n",
    "            duration = ied_durations,  # Durations calculated from start and end times\n",
    "            description = [\"IED\"] * len(start_ied_events), # Description for the events\n",
    "            orig_time = raw.info[\"meas_date\"]\n",
    "        )\n",
    "\n",
    "        # Plot events with the event dict\n",
    "        fig = mne.viz.plot_events(all_events, raw.info['sfreq'], event_id = event_dict, on_missing = 'ignore')\n",
    "\n",
    "        # Print the new IED annotations for verification\n",
    "        print(ied_annotation)\n",
    "\n",
    "        # Set the new annotations while keeping the existing ones\n",
    "        raw.set_annotations(raw.annotations + ied_annotation)\n",
    "\n",
    "        # Drop bad channels as needed\n",
    "        raw.drop_channels(raw.info['bads'])\n",
    "    else:\n",
    "        print(\"No valid IED annotations were created.\")\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read triggers as events / annotations \n",
    "print(len(raw.annotations))\n",
    "mne.count_annotations(raw.annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to create the custom mapping\n",
    "custom_mapping = {annot['description']: assign_event_id(annot['description']) for annot in raw.annotations}\n",
    "\n",
    "# Remove entries with None values (ignored annotations)\n",
    "custom_mapping = {k: v for k, v in custom_mapping.items() if v is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract events from annotations using the custom mapping\n",
    "all_events, all_event_id = mne.events_from_annotations(raw, event_id = custom_mapping) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define event IDs for \"4 Letters\" and IED\n",
    "stim_id = {\"4 Letters\": 100,}\n",
    "ied_id = { \"start\": 66, \"end\": 77,}\n",
    "\n",
    "event_dict = stim_id.copy()\n",
    "event_dict.update(ied_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract start and end times based on event IDs\n",
    "start_ied_events = all_events[all_events[:, 2] == ied_id[\"start\"]][:, 0] / raw.info['sfreq']\n",
    "end_ied_events = all_events[all_events[:, 2] == ied_id[\"end\"]][:, 0] / raw.info['sfreq']\n",
    "\n",
    "# Combine start and end events into one list for ordered processing\n",
    "all_ied_events = sorted(\n",
    "    [(event, 'start') for event in start_ied_events] + [(event, 'end') for event in end_ied_events]\n",
    ")\n",
    "\n",
    "# Ensure correct pairing of start and end events\n",
    "paired_events = make_paired_events(all_ied_events)\n",
    "\n",
    "# Create annotations based on the paired events\n",
    "raw = create_paired_events (paired_events, raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark and drop bad segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open with \"a\" then \"enter\" and drag \n",
    "scalings = dict(eeg = 50e-6)\n",
    "raw.plot(duration = 20, scalings = scalings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if IED is within the epoch\n",
    "def is_ied_within_epoch(epoch_start, epoch_end, ied_annotations):\n",
    "    for annot in ied_annotations:\n",
    "        ied_start = annot['onset']\n",
    "        ied_end = ied_start + annot['duration']\n",
    "        if (ied_start < epoch_end) and (ied_end > epoch_start):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom mapping of annotations to event IDs\n",
    "custom_mapping = {\n",
    "    \"101\": 100, \n",
    "    \"102\": 100, \n",
    "    \"103\": 100, \n",
    "    \"104\": 100, \n",
    "    \"105\": 100, \n",
    "    \"IED\": 88\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract events from annotations\n",
    "all_events, all_event_id = mne.events_from_annotations(raw, event_id=custom_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define event IDs for \"4 Letters\" and IED\n",
    "stim_id = {\"4 Letters\": 100}\n",
    "ied_id = {\"IED\": 88}\n",
    "\n",
    "# Define epochs parameters\n",
    "tmin = -1  # start of the epoch (before the \"4 Letters\" event)\n",
    "tmax = 1   # end of the epoch (after the \"4 Letters\" event)\n",
    "\n",
    "# Create epochs based on \"4 Letters\" events\n",
    "epochs = mne.Epochs(raw, events = all_events, event_id = stim_id, tmin = tmin, tmax = tmax, baseline = (-0.2,0), preload = True, reject_by_annotation = ['bad'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_ied(epochs) :\n",
    "    # Initialize lists to store epochs with and without \"IED\"\n",
    "    epochs_with_ied = []\n",
    "    epochs_without_ied = []\n",
    "\n",
    "    # Initialize lists to store metadata for each epoch\n",
    "    metadata_with_ied = []\n",
    "    metadata_without_ied = []\n",
    "\n",
    "\n",
    "    # Iterate through epochs to check for \"IED\" annotations\n",
    "    for epoch_idx, epoch in enumerate(epochs):\n",
    "        # Get the start and end times of the current epoch in seconds\n",
    "        epoch_start = epochs[epoch_idx].events[0, 0] / raw.info['sfreq'] + tmin\n",
    "        epoch_end = epoch_start + (tmax - tmin)\n",
    "        \n",
    "        # Check if any part of the IED event overlaps with the epoch time range\n",
    "        ied_annotations_within_epoch = [annot for annot in raw.annotations if annot['description'] == 'IED']\n",
    "        \n",
    "        if is_ied_within_epoch(epoch_start, epoch_end, ied_annotations_within_epoch):\n",
    "            #epochs_with_ied.append(epoch_idx)\n",
    "            metadata_with_ied.append({'description': 'With IED'})\n",
    "        else:\n",
    "            #epochs_without_ied.append(epoch_idx)\n",
    "            metadata_without_ied.append({'description': 'Without IED'})\n",
    "    return metadata_with_ied, metadata_without_ied\n",
    "\n",
    "metadata_with_ied, metadata_without_ied = epoch_ied(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metadata DataFrame\n",
    "metadata = pd.DataFrame(metadata_with_ied + metadata_without_ied)\n",
    "\n",
    "# Add metadata to epochs\n",
    "epochs.metadata = metadata\n",
    "\n",
    "# Select epochs with and without IED\n",
    "epochs_with_ied = epochs[metadata['description'] == 'With IED']\n",
    "epochs_without_ied = epochs[metadata['description'] == 'Without IED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of epochs before dropping (initial number of epochs created)\n",
    "total_epochs_created = len(epochs.drop_log)\n",
    "\n",
    "# Number of epochs dropped due to bad annotations\n",
    "bad_dropped_epochs = [log for log in epochs.drop_log if 'BAD_' in log]\n",
    "bad_dropped_count = len(bad_dropped_epochs)\n",
    "\n",
    "# Number of epochs kept (total created - bad dropped)\n",
    "epochs_kept_count = total_epochs_created - bad_dropped_count\n",
    "\n",
    "# Calculate the proportion of dropped epochs relative to the epochs kept\n",
    "proportion_dropped_bad = bad_dropped_count / total_epochs_created\n",
    "\n",
    "# Output the results\n",
    "print(f\"Total epochs created: {total_epochs_created}\")\n",
    "print(f\"Number of epochs dropped due to bad annotations: {bad_dropped_count}\")\n",
    "print(f\"Proportion of epochs dropped due to bad annotations: {proportion_dropped_bad:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here reject bad epochs manually\n",
    "epochs.plot(n_epochs = 10, events = all_events, event_id = event_dict, scalings = scalings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export epoched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe_as_csv(dataframe, base_path, base_filename, suffix):\n",
    "    try:\n",
    "        # Construct the full file path\n",
    "        csv_filename = f\"{base_filename}{suffix}.csv\"\n",
    "        file_path = os.path.join(base_path, csv_filename)\n",
    "        \n",
    "        # Ensure the target directory exists\n",
    "        os.makedirs(base_path, exist_ok=True)\n",
    "        \n",
    "        # Save the dataframe to CSV\n",
    "        dataframe.to_data_frame().to_csv(file_path)\n",
    "        logging.info(f\"Dataframe saved to: {file_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save dataframe {suffix}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "\n",
    "# Extract the EPI number and file name from the input file path\n",
    "parts = file_path.split('/')\n",
    "epi_number = parts[-2]  \n",
    "filename = parts[-1]\n",
    "\n",
    "# Construct the base file path\n",
    "base_filename = filename.replace('.fif', '')  # Removing the extension for flexibility\n",
    "\n",
    "#############PATH FILE#################\n",
    "base_path = os.path.join(base_directory_path, epi_number)\n",
    "\n",
    "# Save dataframe to CSV\n",
    "save_dataframe_as_csv(epochs, base_path, base_filename, '_epochs')\n",
    "save_dataframe_as_csv(epochs_with_ied, base_path, base_filename, '_epochs_with_IED')\n",
    "save_dataframe_as_csv(epochs_without_ied, base_path, base_filename, '_epochs_without_IED')\n",
    "\n",
    "# Save the epochs to a .fif file\n",
    "epochs.save(f'{base_path}/{base_filename}_epochs.fif', overwrite = True)\n",
    "epochs_with_ied.save(f'{base_path}/{base_filename}_epochs_with_IED.fif', overwrite = True)\n",
    "epochs_without_ied.save(f'{base_path}/{base_filename}_epochs_without_IED.fif', overwrite = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neo-0.13.1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
